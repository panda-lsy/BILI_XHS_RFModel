{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¤¾äº¤åª’ä½“è¯„è®ºç‚¹èµé¢„æµ‹ç³»ç»Ÿ\n",
    "\n",
    "## é¡¹ç›®æ¦‚è¿°\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„ç¤¾äº¤åª’ä½“è¯„è®ºç‚¹èµæ•°é¢„æµ‹ç³»ç»Ÿï¼Œä¸“é—¨é’ˆå¯¹Bç«™å’Œå°çº¢ä¹¦ä¸¤å¤§å¹³å°çš„ç”¨æˆ·è¯„è®ºè¿›è¡Œåˆ†æå’Œé¢„æµ‹ã€‚è¯¥ç³»ç»Ÿä½¿ç”¨éšæœºæ£®æ—å›å½’ç®—æ³•ï¼Œé€šè¿‡åˆ†æè¯„è®ºçš„å„ç§ç‰¹å¾ï¼ˆå¦‚è¯„è®ºé•¿åº¦ã€å‘å¸ƒæ—¶é—´ã€æ˜¯å¦å«è¡¨æƒ…ç­‰ï¼‰ï¼Œé¢„æµ‹è¯„è®ºå¯èƒ½è·å¾—çš„ç‚¹èµæ•°é‡ï¼Œä¸ºå†…å®¹åˆ›ä½œè€…å’Œç¤¾äº¤åª’ä½“è¥é”€äººå‘˜æä¾›æ•°æ®æ”¯æŒã€‚\n",
    "\n",
    "## æ ¸å¿ƒåŠŸèƒ½\n",
    "\n",
    "1. **æ•°æ®å¤„ç†å’Œç‰¹å¾å·¥ç¨‹**\n",
    "   - æ”¯æŒç»Ÿä¸€å¤„ç†Bç«™å’Œå°çº¢ä¹¦çš„è¯„è®ºæ•°æ®\n",
    "   - è‡ªåŠ¨æå–è¯„è®ºç‰¹å¾ï¼ˆè¯„è®ºé•¿åº¦ã€è¡¨æƒ…ä½¿ç”¨ã€å‘å¸ƒæ—¶æ®µç­‰ï¼‰\n",
    "   - é’ˆå¯¹ä¸åŒå¹³å°æå–ç‰¹å®šç‰¹å¾ï¼ˆBç«™ç”¨æˆ·ç­‰çº§ã€å°çº¢ä¹¦IPåœ°å€ç­‰ï¼‰\n",
    "\n",
    "2. **æ¨¡å‹è®­ç»ƒä¸ç®¡ç†**\n",
    "   - è®­ç»ƒæ–°æ¨¡å‹æˆ–åŸºäºç°æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒ\n",
    "   - è‡ªåŠ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆMSEã€RÂ²è¯„åˆ†ï¼‰\n",
    "   - å¯è§†åŒ–å±•ç¤ºç‰¹å¾é‡è¦æ€§å’Œé¢„æµ‹æ•ˆæœ\n",
    "   - æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œæ—¶é—´æˆ³å‘½å\n",
    "\n",
    "3. **ç‚¹èµæ•°é¢„æµ‹**\n",
    "   - åŸºäºè®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹è¯„è®ºç‚¹èµæ½œåŠ›\n",
    "   - æ”¯æŒé€‰æ‹©ä¸åŒæ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "   - æ ¹æ®å¹³å°å·®å¼‚åŠ¨æ€è°ƒæ•´è¾“å…¥ç‰¹å¾\n",
    "   - è®°å½•å’Œå¯¼å‡ºé¢„æµ‹ç»“æœ\n",
    "\n",
    "## æŠ€æœ¯ç‰¹ç‚¹\n",
    "\n",
    "- **æ•°æ®å¤„ç†**ï¼šä½¿ç”¨pandasè¿›è¡Œé«˜æ•ˆæ•°æ®å¤„ç†å’Œè½¬æ¢\n",
    "- **æœºå™¨å­¦ä¹ **ï¼šåŸºäºscikit-learnçš„RandomForestRegressorå®ç°å›å½’é¢„æµ‹\n",
    "- **å¯è§†åŒ–**ï¼šåˆ©ç”¨matplotlibå’Œseabornå±•ç¤ºæ¨¡å‹æ€§èƒ½å’Œç‰¹å¾é‡è¦æ€§\n",
    "- **ç”¨æˆ·ç•Œé¢**ï¼šåŸºäºipywidgetsæ„å»ºäº¤äº’å¼Jupyterç•Œé¢ï¼Œæ”¯æŒç›´è§‚æ“ä½œ\n",
    "- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„é”™è¯¯æç¤ºå’Œå¼‚å¸¸å¤„ç†æœºåˆ¶\n",
    "\n",
    "## ä½¿ç”¨åœºæ™¯\n",
    "\n",
    "1. **å†…å®¹åˆ›ä½œä¼˜åŒ–**ï¼šå¸®åŠ©åˆ›ä½œè€…é¢„æµ‹è¯„è®ºè·èµæ½œåŠ›ï¼Œä¼˜åŒ–è¡¨è¾¾æ–¹å¼\n",
    "2. **ç¤¾äº¤åª’ä½“è¥é”€**ï¼šä¸ºè¥é”€äººå‘˜æä¾›è¯„è®ºæ•ˆæœé¢„æµ‹ï¼Œåˆ¶å®šæ›´æœ‰æ•ˆçš„äº’åŠ¨ç­–ç•¥\n",
    "3. **ç”¨æˆ·è¡Œä¸ºç ”ç©¶**ï¼šåˆ†æä¸åŒå¹³å°ç”¨æˆ·çš„ç‚¹èµè¡Œä¸ºç‰¹å¾å’Œåå¥½\n",
    "4. **å†…å®¹è¿è¥å†³ç­–**ï¼šä¸ºå¹³å°è¿è¥æä¾›æ•°æ®æ”¯æŒï¼Œäº†è§£ç”¨æˆ·äº’åŠ¨æ¨¡å¼\n",
    "\n",
    "## é¡¹ç›®ç‰¹è‰²\n",
    "\n",
    "- **è·¨å¹³å°åˆ†æ**ï¼šåŒæ—¶æ”¯æŒBç«™å’Œå°çº¢ä¹¦ä¸¤ä¸ªä¸»æµå¹³å°çš„æ•°æ®åˆ†æ\n",
    "- **ç‰¹å¾å·®å¼‚åŒ–**ï¼šæ ¹æ®ä¸åŒå¹³å°çš„ç‰¹ç‚¹æå–å’Œå¤„ç†ç‰¹å®šç‰¹å¾\n",
    "- **æ¨¡å‹å¯æ‰©å±•æ€§**ï¼šæ”¯æŒæ¨¡å‹è¿­ä»£æ›´æ–°å’Œå¤šç‰ˆæœ¬ç®¡ç†\n",
    "- **ç”¨æˆ·å‹å¥½ç•Œé¢**ï¼šç›´è§‚çš„æ“ä½œç•Œé¢ï¼Œé™ä½ä½¿ç”¨é—¨æ§›\n",
    "- **å¯è§†åŒ–æ´å¯Ÿ**ï¼šæä¾›ä¸°å¯Œçš„å¯è§†åŒ–ç»“æœï¼Œå¸®åŠ©ç†è§£æ¨¡å‹é¢„æµ‹é€»è¾‘\n",
    "\n",
    "é€šè¿‡è¿™ä¸ªç³»ç»Ÿï¼Œç”¨æˆ·å¯ä»¥æ·±å…¥äº†è§£å½±å“è¯„è®ºç‚¹èµæ•°çš„å…³é”®å› ç´ ï¼Œé¢„æµ‹è¯„è®ºçš„äº’åŠ¨æ½œåŠ›ï¼Œä»è€Œåˆ¶å®šæ›´æœ‰æ•ˆçš„å†…å®¹ç­–ç•¥å’Œäº’åŠ¨æ–¹æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ•°æ®å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ä»£ç å—åˆ†æ\n",
    "\n",
    "ç¬¬ä¸€ä¸ªä»£ç å—å®ç°äº†ä»åŸå§‹Excelæ–‡ä»¶åˆ°ç»“æ„åŒ–æ•°æ®é›†çš„è½¬æ¢è¿‡ç¨‹ï¼Œä¸»è¦å®Œæˆä»¥ä¸‹åŠŸèƒ½ï¼š\n",
    "\n",
    "## 1. æ•°æ®å¯¼å…¥ä¸æ•´åˆ\n",
    "- å¼•å…¥å¿…è¦çš„åº“ï¼š`os`, `pandas`, `re`\n",
    "- åˆ†åˆ«è¯»å–Bç«™å’Œå°çº¢ä¹¦çš„Excelè¯„è®ºæ•°æ®æ–‡ä»¶\n",
    "- å¤„ç†ä¸åŒæ ¼å¼çš„æ•°æ®æºï¼Œç»Ÿä¸€å­—æ®µåå’Œæ•°æ®ç»“æ„\n",
    "\n",
    "## 2. å¹³å°ç‰¹å®šæ•°æ®å¤„ç†\n",
    "- **Bç«™æ•°æ®å¤„ç†**:\n",
    "  - æå–å¸–å­æ ‡é¢˜ä¿¡æ¯\n",
    "  - å°†\"ä¸€çº§è¯„è®º\"ã€\"äºŒçº§è¯„è®º\"ç­‰æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—æ ‡è¯†\n",
    "  - å¤„ç†ç”¨æˆ·æ€§åˆ«ã€ç­‰çº§ç­‰ç‰¹æœ‰å­—æ®µ\n",
    "  - è®¡ç®—äºŒçº§å›å¤æ•°é‡ä½œä¸ºäº’åŠ¨æŒ‡æ ‡\n",
    "\n",
    "- **å°çº¢ä¹¦æ•°æ®å¤„ç†**:\n",
    "  - ç»Ÿä¸€æ—¶é—´æ ¼å¼\n",
    "  - å¤„ç†IPåœ°å€ä¿¡æ¯\n",
    "  - æå–è¯„è®ºå…³ç³»å’ŒäºŒçº§å›å¤æ•°æ®\n",
    "\n",
    "## 3. ç‰¹å¾å·¥ç¨‹\n",
    "- åˆ›å»ºè¯„è®ºå­—æ•°ç»Ÿè®¡ç‰¹å¾\n",
    "- è¯†åˆ«è¯„è®ºä¸­çš„è¡¨æƒ…ç¬¦å· `[xxx]`\n",
    "- å¯¹Bç«™æ•°æ®ï¼Œå¤„ç†å‘å¸ƒæ—¶æ®µï¼ˆæ—©/ä¸­/æ™šï¼‰\n",
    "- å¯¹ç”¨æˆ·ç­‰çº§è¿›è¡Œåˆ†ç±»ï¼ˆèµ„æ·±ç”¨æˆ·/æ™®é€šç”¨æˆ·ï¼‰\n",
    "- åˆ›å»ºäº’åŠ¨å€¼æŒ‡æ ‡ï¼šBç«™ä½¿ç”¨äºŒçº§è¯„è®ºæ•°ï¼Œå°çº¢ä¹¦ä½¿ç”¨äºŒçº§è¯„è®ºæ•°/10\n",
    "\n",
    "## 4. æ•°æ®ä¿å­˜ä¸è¾“å‡º\n",
    "- åˆå¹¶å¤„ç†åçš„æ•°æ®é›†\n",
    "- ä½¿ç”¨æ—¶é—´æˆ³å‘½åå¹¶ä¿å­˜ä¸ºExcelæ–‡ä»¶\n",
    "- è¾“å‡ºå¤„ç†ç»Ÿè®¡ä¿¡æ¯å’Œæ ·æœ¬æ•°æ®\n",
    "\n",
    "è¿™æ®µä»£ç å±•ç¤ºäº†é’ˆå¯¹ç¤¾äº¤åª’ä½“è¯„è®ºæ•°æ®çš„ä¸“ä¸šETLï¼ˆæå–-è½¬æ¢-åŠ è½½ï¼‰æµç¨‹ï¼Œä¸ºåç»­çš„æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæä¾›äº†ç»“æ„åŒ–ã€æ ‡å‡†åŒ–çš„æ•°æ®é›†ã€‚ä»å¤„ç†ç»“æœå¯ä»¥çœ‹å‡ºï¼Œæœ€ç»ˆåˆå¹¶çš„æ•°æ®é›†åŒ…å«750æ¡è®°å½•å’Œ12ä¸ªå­—æ®µï¼Œä¸ºè¯„è®ºç‚¹èµé¢„æµ‹å¥ å®šäº†åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['å°æ¨Johnson', 'ç”·', 'å°ç¾Šæ‘è¿˜å¾—æ˜¯å°æ¨æ¥[å®³ç¾]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(6179), '2025-03-21 23:03:27', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output22.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['å°æ¨Johnson', 'ç”·', 'å°ç¾Šæ‘è¿˜å¾—æ˜¯å°æ¨æ¥[å®³ç¾]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(6179), '2025-03-21 23:03:27', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_1.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸‰ä¸ä¸‰åä¸‡æ‚£è€…', 'ç”·', '00:11 å¯çˆ±æ', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(18), '2025-03-18 11:01:58', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_10.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['åŒæŒå†°æ·‡æ·‹', 'ä¿å¯†', 'è§†é¢‘é‡Œè¯´å–œæ¬¢çš„ä½ äººä¸€èˆ¬ä¸ä¼šè¯„è®ºï¼Œé‚£å°±è¯„è®ºä¸‹å§â€¦â€¦â€¦\\n19å¹´çš„è€ç²‰ä¸ï¼Œå¹¶ä¸”ç»å¸¸çœ‹ç›´æ’­ï¼Œè¡¨ç¤ºå¤§ç¥¥å“¥è¿™äººå°±æ˜¯æ‹§å·´ã€çˆ±é¢å„¿ã€çˆ±å¾—ç‘Ÿã€è—ä¸ä½äº‹ï¼Œä½†ç¡®å®å¾ˆçœŸè¯šï¼Œç®€ç›´å°±æ˜¯éª—å­çœ¼é‡Œæœ€å®Œç¾çš„è¢«éª—å¯¹è±¡[å–œæè€Œæ³£]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(12015), '2025-03-25 21:24:47', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_11.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æ¼«è¡Œæ˜Ÿ', 'ä¿å¯†', 'æ±½çƒ§éƒ½å¾ˆéš¾ï¼Œåˆ«è¯´ç”¨æŸ´çƒ§äº†', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(38), '2025-03-27 00:32:39', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_12.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸€æ¡å“ä¹Ÿ', 'ä¿å¯†', 'è¯¥ä¸‹æ‰‹å¥¹æ˜¯çœŸä¸‹æ‰‹[ç¬‘å“­]', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(123), '2025-03-28 14:00:56', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_13.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['è¿›å‡»çš„é©¬æ¥¼', 'ä¿å¯†', 'ä¸‰ä»£å–‚é¸½äººå‘Šè¯‰ä½ ï¼Œè¿™æ ·å–‚é¸½å­æ°¸è¿œä¸ä¼šå›å®¶ï¼Œä»å°å–‚åˆ°å¤§çš„é¸½å­è®¤è¯†å®¶ï¼Œè¿™ç§ä¹°æ¥çš„ï¼Œä½ çš„å¤©å¤©æ”¾é˜³å°è®©å®ƒçœ‹å¤–é¢ï¼Œä¹Ÿä¸èƒ½æ”¾ï¼Œç­‰å®ƒç”Ÿä»”ï¼Œè¦ç”Ÿå‡ æ¬¡åæ‰èƒ½è¯•ç€æ‰“å¼€ï¼Œå› ä¸ºæœ‰å´½äº†æœ‰çš„é¸½å­å°±ä¸èµ°äº†ï¼Œä½†å¾ˆå¤šé¸½å­å½’å·¢æ„è¯†å¼ºçš„è¿˜æ˜¯ä¼šå›ä»¥å‰çš„å®¶ï¼Œä½ è¿™æ ·å–‚æ°¸è¿œå–‚ä¸å®¶çš„[åƒç“œ]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(2109), '2025-03-27 18:59:35', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_14.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æªå¼¹è½¨è¿¹', 'ç”·', 'RIP  æ²¡æƒ³åˆ°å¦‚æ­¤çªç„¶ï¼Œç¬¬ä¸€æ¬¡åšé¢ç­‹å“¥é¬¼ç•œè¿˜æ˜¯åœ¨18å¹´', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(1600), '2025-03-29 11:40:47', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_15.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['è¿›å‡»çš„é©¬æ¥¼', 'ä¿å¯†', 'ä¸‰ä»£å–‚é¸½äººå‘Šè¯‰ä½ ï¼Œè¿™æ ·å–‚é¸½å­æ°¸è¿œä¸ä¼šå›å®¶ï¼Œä»å°å–‚åˆ°å¤§çš„é¸½å­è®¤è¯†å®¶ï¼Œè¿™ç§ä¹°æ¥çš„ï¼Œä½ çš„å¤©å¤©æ”¾é˜³å°è®©å®ƒçœ‹å¤–é¢ï¼Œä¹Ÿä¸èƒ½æ”¾ï¼Œç­‰å®ƒç”Ÿä»”ï¼Œè¦ç”Ÿå‡ æ¬¡åæ‰èƒ½è¯•ç€æ‰“å¼€ï¼Œå› ä¸ºæœ‰å´½äº†æœ‰çš„é¸½å­å°±ä¸èµ°äº†ï¼Œä½†å¾ˆå¤šé¸½å­å½’å·¢æ„è¯†å¼ºçš„è¿˜æ˜¯ä¼šå›ä»¥å‰çš„å®¶ï¼Œä½ è¿™æ ·å–‚æ°¸è¿œå–‚ä¸å®¶çš„[åƒç“œ]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(3551), '2025-03-27 18:59:35', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_15_1.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['è¿›å‡»çš„é©¬æ¥¼', 'ä¿å¯†', 'ä¸‰ä»£å–‚é¸½äººå‘Šè¯‰ä½ ï¼Œè¿™æ ·å–‚é¸½å­æ°¸è¿œä¸ä¼šå›å®¶ï¼Œä»å°å–‚åˆ°å¤§çš„é¸½å­è®¤è¯†å®¶ï¼Œè¿™ç§ä¹°æ¥çš„ï¼Œä½ çš„å¤©å¤©æ”¾é˜³å°è®©å®ƒçœ‹å¤–é¢ï¼Œä¹Ÿä¸èƒ½æ”¾ï¼Œç­‰å®ƒç”Ÿä»”ï¼Œè¦ç”Ÿå‡ æ¬¡åæ‰èƒ½è¯•ç€æ‰“å¼€ï¼Œå› ä¸ºæœ‰å´½äº†æœ‰çš„é¸½å­å°±ä¸èµ°äº†ï¼Œä½†å¾ˆå¤šé¸½å­å½’å·¢æ„è¯†å¼ºçš„è¿˜æ˜¯ä¼šå›ä»¥å‰çš„å®¶ï¼Œä½ è¿™æ ·å–‚æ°¸è¿œå–‚ä¸å®¶çš„[åƒç“œ]', np.float64(nan), 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(3552), '2025-03-27 18:59:35', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_16.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['7é²¸å°¾', 'ç”·', 'ç¬¬äºŒå¤©ä¼šæ›´å¥½çš„å…„å¼Ÿä»¬', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(77171), '2025-03-29 17:17:07', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_17.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['è¥¿ç“œé…¥Su', 'ä¿å¯†', 'å´©åå¼€å§‹å‘åŠ›äº†å—ï¼Ÿè¿™å‰§æƒ…å¤ªç”œå•¦[å´©åï¼šæ˜Ÿç©¹é“é“_å“­]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(254), '2025-03-31 13:55:24', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_18.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['è¥¿ç“œé…¥Su', 'ä¿å¯†', 'å´©åå¼€å§‹å‘åŠ›äº†å—ï¼Ÿè¿™å‰§æƒ…å¤ªç”œå•¦[å´©åï¼šæ˜Ÿç©¹é“é“_å“­]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(528), '2025-03-31 13:55:24', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_19.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸‰ä¸ä¸‰åä¸‡æ‚£è€…', 'ç”·', '00:11 å¯çˆ±æ', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(18), '2025-03-18 11:01:58', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_2.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['èŠ±èŠ±ä¸åªæ˜¯å¥½çœ‹è€Œå·²', 'ä¿å¯†', 'æç»´åˆšçš„æ—¥å¸¸âœ˜\\næç»´åˆšå’Œé±¼å¡˜âœ”', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(1515), '2025-03-19 15:05:00', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_20.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['èŠ±èŠ±ä¸åªæ˜¯å¥½çœ‹è€Œå·²', 'ä¿å¯†', 'æç»´åˆšçš„æ—¥å¸¸âœ˜\\næç»´åˆšå’Œé±¼å¡˜âœ”', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(1515), '2025-03-19 15:05:00', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_21.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ç©ºæ— -å¤©æ®›', 'ä¿å¯†', '04:55 ä¸å–œæ¬¢æ‘é—ªé¿å¾—å°æœ‹å‹ä»¬å¤§å®¶å¥½å•Šï¼Œæˆ‘æ˜¯è¶…é›„å¤é¾™ï¼Œæ˜¯çš„å­©å­ä»¬ï¼Œæˆ‘è¿›å…¨æ¯äº†[æ˜Ÿæ˜Ÿçœ¼]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(87), '2025-03-21 20:05:35', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_23.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['å°æ¨Johnson', 'ç”·', 'å°ç¾Šæ‘è¿˜å¾—æ˜¯å°æ¨æ¥[å®³ç¾]', np.float64(nan), 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(8715), '2025-03-21 23:03:27', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_24.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['åæ­£æˆ‘æ˜¯ç‰›ç‰›', 'ä¿å¯†', 'æ–°é¢–çš„å‰ªè¾‘é£æ ¼å’Œaiå¥³ä¸»ç‹¬ç™½è®©äººè€³ç›®ä¸€æ–°ï¼Œåƒæ˜¯å¬ä¸€ä½ä¸¾æ‰‹æŠ•è¶³ç«¯åº„ä¼˜é›…çš„é•¿è€…è®²è¿°è‡ªå·±çš„è¿‡å¾€ï¼Œæ„Ÿæ…¨æ·¡ç„¶è±è¾¾çš„äººç”Ÿæ€åº¦ç«Ÿæ˜¯æºäºå¦‚æ­¤è·Œå®•èµ·ä¼çš„ç»å†ï¼Œæ„Ÿè°¢upçš„ç”¨å¿ƒåˆ›ä½œè®©æˆ‘æœ‰å¹¸æ¬£èµåˆ«å…·ä¸€æ ¼çš„è§£è¯´è§†é¢‘ï¼Œå¸Œæœ›upè¶Šæ¥è¶Šå¥½[ä¿å«èåœ_å“‡]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(426), '2025-03-22 15:08:07', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_25.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æç™½ä¸å–XO', 'ä¿å¯†', 'ä¸€æ‹³æ‰“å‡º10ä¸‡å¹´é­‚ç¯ï¼Œå®åŠ›ææ€–å¦‚å®[å¦™å•Š]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(189), '2025-03-22 18:47:59', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_26.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æç™½ä¸å–XO', 'ä¿å¯†', 'ä¸€æ‹³æ‰“å‡º10ä¸‡å¹´é­‚ç¯ï¼Œå®åŠ›ææ€–å¦‚å®[å¦™å•Š]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(557), '2025-03-22 18:47:59', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_27.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸‰è¼__', 'ä¿å¯†', 'æ²¡äººæ³¨æ„è¿™æ˜¯æ¹¿èº«æ•ˆæœå—ğŸ‘€', np.float64(nan), 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(21), '2025-03-23 12:46:03', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_28.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['å¤§å®¶çš„éŸ³ä¹æœº', 'ä¿å¯†', 'è¶…æƒŠå–œçš„æ¢¦å¹»è”åŠ¨ï¼ä¸‹ä¸€æœŸä¼šæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ[æ˜Ÿæ˜Ÿçœ¼]æ›´å¤šæ±ªè‹æ³·æ¼”å”±ä¼šæ´»åŠ¨æŒ‡è·¯ï¼ŒæŠ•ç¨¿æœ‰æœºä¼šè·å¾—ç¿»ç‰Œå’Œç­¾åç…§å“¦ğŸ‘‰https://www.bilibili.com/v/topic/detail/?topic_id=1290686', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(1225), '2025-03-25 15:41:14', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_3.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ç©ºæ— -å¤©æ®›', 'ä¿å¯†', '04:55 ä¸å–œæ¬¢æ‘é—ªé¿å¾—å°æœ‹å‹ä»¬å¤§å®¶å¥½å•Šï¼Œæˆ‘æ˜¯è¶…é›„å¤é¾™ï¼Œæ˜¯çš„å­©å­ä»¬ï¼Œæˆ‘è¿›å…¨æ¯äº†[æ˜Ÿæ˜Ÿçœ¼]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(87), '2025-03-21 20:05:35', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_4.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['å°æ¨Johnson', 'ç”·', 'å°ç¾Šæ‘è¿˜å¾—æ˜¯å°æ¨æ¥[å®³ç¾]', np.float64(nan), 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(8715), '2025-03-21 23:03:27', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_5.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['åæ­£æˆ‘æ˜¯ç‰›ç‰›', 'ä¿å¯†', 'æ–°é¢–çš„å‰ªè¾‘é£æ ¼å’Œaiå¥³ä¸»ç‹¬ç™½è®©äººè€³ç›®ä¸€æ–°ï¼Œåƒæ˜¯å¬ä¸€ä½ä¸¾æ‰‹æŠ•è¶³ç«¯åº„ä¼˜é›…çš„é•¿è€…è®²è¿°è‡ªå·±çš„è¿‡å¾€ï¼Œæ„Ÿæ…¨æ·¡ç„¶è±è¾¾çš„äººç”Ÿæ€åº¦ç«Ÿæ˜¯æºäºå¦‚æ­¤è·Œå®•èµ·ä¼çš„ç»å†ï¼Œæ„Ÿè°¢upçš„ç”¨å¿ƒåˆ›ä½œè®©æˆ‘æœ‰å¹¸æ¬£èµåˆ«å…·ä¸€æ ¼çš„è§£è¯´è§†é¢‘ï¼Œå¸Œæœ›upè¶Šæ¥è¶Šå¥½[ä¿å«èåœ_å“‡]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(426), '2025-03-22 15:08:07', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_6.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æç™½ä¸å–XO', 'ä¿å¯†', 'ä¸€æ‹³æ‰“å‡º10ä¸‡å¹´é­‚ç¯ï¼Œå®åŠ›ææ€–å¦‚å®[å¦™å•Š]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(189), '2025-03-22 18:47:59', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_7.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æç™½ä¸å–XO', 'ä¿å¯†', 'ä¸€æ‹³æ‰“å‡º10ä¸‡å¹´é­‚ç¯ï¼Œå®åŠ›ææ€–å¦‚å®[å¦™å•Š]', nan, 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(557), '2025-03-22 18:47:59', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_8.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸‰è¼__', 'ä¿å¯†', 'æ²¡äººæ³¨æ„è¿™æ˜¯æ¹¿èº«æ•ˆæœå—ğŸ‘€', np.float64(nan), 'ä¸€çº§è¯„è®º', np.int64(6), np.int64(21), '2025-03-23 12:46:03', np.float64(nan)]\n",
      "å¤„ç†Bç«™æ–‡ä»¶: comment_output_9.xlsx\n",
      "Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['åŒ–æµ·æ¡‘ç”°', 'ä¿å¯†', 'å­©å­ï¼Œä¸è¦æ‚²ä¼¤ï¼Œä¸è¦å“­æ³£ã€‚\\næ€»æœ‰åœ°æ–¹ä½ èƒ½å‘å…‰å‘çƒ­çš„ï¼Œ æ¯”å¦‚[doge_é‡‘ç®]', nan, 'ä¸€çº§è¯„è®º', np.int64(5), np.int64(406), '2025-03-24 21:11:40', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['momo', 'ä½ å¤¸å¤¸å¥¹å•Šï¼Œå¤šé™ªé™ªå¥¹å•Šï¼Œåˆ«å˜´ä¸Šè¯´è¯´ï¼Œå¥³æœ‹å‹è¿™æ ·å¥¹ä¹Ÿä¸æƒ³', 'æ—¶é›¨', 'ä¸€çº§è¯„è®º', 'æ±Ÿè¥¿', np.int64(61), np.int64(7), '2025/03/29', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_1.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸æ˜¯å¥¶ç¾”', 'å…³æ³¨+ç‚¹èµæ”¶è— æ¯æ»¡200æœ‹å‹åœˆæŠ½é€ä¸€éƒ¨16pm', 'ä¸æ˜¯å¥¶ç¾”', 'ä¸€çº§è¯„è®º', 'æµ™æ±Ÿ', np.int64(253), np.int64(111), '2025/03/29', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_2.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['å¥½è¿é™ä¸´é¦–ä½é€‰æ‰‹', 'æ±‚æ±‚ä¸€å¥—é“¾æ¥', '-ä¼Šæ…§', 'ä¸€çº§è¯„è®º', 'æ²³å—', np.int64(3), np.int64(2), '2025/03/30', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_3.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['æˆ‘æ˜¯ä½ çˆ¸çˆ¸', 'åœ¨å“ªç›´æ’­ï¼Œæ˜¯2å·10ç‚¹å—', 'å›¾å›¾æ¯å¤©ä¸èµ·æ—©ğŸ“', 'ä¸€çº§è¯„è®º', 'é™•è¥¿', np.int64(1), np.int64(4), '2025/03/31', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_4.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ukin.', 'æ–°æ­Œå…¨å…¬å¼€å—ã€é‚£scè¿˜çœ‹ä»€ä¹ˆ', 'äº‘æš®', 'ä¸€çº§è¯„è®º', 'å¹¿è¥¿', np.int64(2), np.int64(2), '2025/03/27', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_5.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['^^æˆ‘å¼€å¿ƒå°±å¥½', 'æˆ‘éƒ½è¦æ€€ç–‘é€‰å›¾çš„stfæ˜¯ä¸æ˜¯å¤ªå«‰å¦’ä»–çš„ç¾è²Œäº†ã€‚ï¼Œ', 'é€—çŒ«æ£’_x', 'ä¸€çº§è¯„è®º', 'å¹¿ä¸œ', np.int64(110), np.int64(4), '2025/03/12', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_6.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['ä¸æ˜¯å¥¶ç¾”', 'å…³æ³¨+ç‚¹èµæ”¶è— æ¯æ»¡200æœ‹å‹åœˆæŠ½é€ä¸€éƒ¨16pm', 'ä¸æ˜¯å¥¶ç¾”', 'ä¸€çº§è¯„è®º', 'æµ™æ±Ÿ', np.int64(253), np.int64(111), '2025/03/29', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_7.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['momo', 'ä½ å¤¸å¤¸å¥¹å•Šï¼Œå¤šé™ªé™ªå¥¹å•Šï¼Œåˆ«å˜´ä¸Šè¯´è¯´ï¼Œå¥³æœ‹å‹è¿™æ ·å¥¹ä¹Ÿä¸æƒ³', 'æ—¶é›¨', 'ä¸€çº§è¯„è®º', 'æ±Ÿè¥¿', np.int64(61), np.int64(7), '2025/03/29', np.float64(nan)]\n",
      "å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: comment_output_backup.xlsx\n",
      "å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: ['^^æˆ‘å¼€å¿ƒå°±å¥½', 'æˆ‘éƒ½è¦æ€€ç–‘é€‰å›¾çš„stfæ˜¯ä¸æ˜¯å¤ªå«‰å¦’ä»–çš„ç¾è²Œäº†ã€‚ï¼Œ', 'é€—çŒ«æ£’_x', 'ä¸€çº§è¯„è®º', 'å¹¿ä¸œ', np.int64(110), np.int64(4), '2025/03/12', np.float64(nan)]\n",
      "åˆå¹¶æ•°æ®é›†å¤§å°: (1906, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33223\\AppData\\Local\\Temp\\ipykernel_28924\\121182624.py:217: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ 0.7  0.7  0.8  0.2  0.   0.   0.   0.3  1.   0.   0.1  0.1  0.3  0.1\n",
      "  0.  11.1  0.   3.3  0.   1.7  0.   0.   0.   1.1  0.   0.   0.   0.5\n",
      "  0.   0.   0.2  0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.   0.\n",
      "  0.   0.4  0.   0.4  0.   0.4  0.   0.   0.   0.1  0.   0.   0.   0.2\n",
      "  0.   0.   0.2  0.   0.2  0.   0.   0.1  0.   0.   0.1  0.   0.1  0.4\n",
      "  0.   0.8  0.   0.4  0.   0.7  0.   0.9  0.   0.7  0.   0.3  0.   0.6\n",
      "  0.   0.6  0.   0.2  0.  11.1  0.   3.3  0.   1.7  0.   0.   0.   1.1\n",
      "  0.   0.   0.   0.5  0.   0.   0.7  0.7  0.8  0.2  0.   0.   0.   0.3\n",
      "  1.   0.   0.1  0.1  0.3  0.1  0.   0.4  0.   0.8  0.   0.4  0.   0.7\n",
      "  0.   0.9  0.   0.7  0.   0.3  0.   0.6  0.   0.6  0.   0.2  0. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_xhs, 'interaction_score'] = df.loc[mask_xhs, 'second_level_reply_count_num'] / 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å·²ä¿å­˜åˆ° final_data_with_features_20250401_170728.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def unify_data(folder_bili='data/BILI', folder_xhs='data/XHS'):\n",
    "    standard_cols = [\n",
    "        'user_nickname','comment_text','replied_user','comment_level',\n",
    "        'likes','reply_time','gender','user_level','ip','second_level_reply_count'\n",
    "    ]\n",
    "\n",
    "    # å¤„ç† Bç«™æ•°æ®\n",
    "    bili_dfs = []\n",
    "    for file in os.listdir(folder_bili):\n",
    "        if file.endswith('.xlsx'):\n",
    "            try:\n",
    "                print(f\"å¤„ç†Bç«™æ–‡ä»¶: {file}\")\n",
    "                # å…ˆè¯»å–ç¬¬ä¸€è¡Œæœ€åä¸€åˆ—ä»¥è·å–å¸–å­æ ‡é¢˜\n",
    "                temp = pd.read_excel(os.path.join(folder_bili, file), header=None)\n",
    "                post_title = str(temp.iloc[0, -1])\n",
    "                # å®é™…æ•°æ®ä»ç¬¬äºŒè¡Œå¼€å§‹ï¼Œä½†ä¸ä½¿ç”¨åˆ—åï¼Œå› ä¸ºæ²¡æœ‰æ ‡é¢˜è¡Œ\n",
    "                df = pd.read_excel(os.path.join(folder_bili, file), skiprows=1, header=None)\n",
    "                \n",
    "                # æ‰“å°åˆ—å†…å®¹ä»¥ä¾¿è°ƒè¯•\n",
    "                print(f\"Bç«™æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: {df.iloc[0].tolist()}\")\n",
    "                \n",
    "                # æ ¹æ®ä½ç½®ç›´æ¥æŒ‡å®šåˆ—å - æ ¹æ®ç¤ºä¾‹æ•°æ®æ¨æ–­\n",
    "                column_names = {\n",
    "                    0: 'user_nickname',  # ç¬¬1åˆ—: ç”¨æˆ·æ˜µç§°\n",
    "                    1: 'gender',         # ç¬¬2åˆ—: æ€§åˆ«\n",
    "                    2: 'comment_text',   # ç¬¬3åˆ—: è¯„è®ºå†…å®¹\n",
    "                    3: 'replied_user',   # ç¬¬4åˆ—: è¢«å›å¤ç”¨æˆ·\n",
    "                    4: 'comment_level_text', # ç¬¬5åˆ—: è¯„è®ºå±‚çº§æè¿°\n",
    "                    5: 'user_level',     # ç¬¬6åˆ—: ç”¨æˆ·ç­‰çº§\n",
    "                    6: 'likes',          # ç¬¬7åˆ—: ç‚¹èµæ•°\n",
    "                    7: 'reply_time',     # ç¬¬8åˆ—: å›å¤æ—¶é—´\n",
    "                }\n",
    "                \n",
    "                # é‡å‘½ååˆ—\n",
    "                df = df.rename(columns=column_names)\n",
    "                \n",
    "                # è½¬æ¢è¯„è®ºå±‚çº§æ–‡æœ¬ä¸ºæ•°å­—: \"ä¸€çº§è¯„è®º\" -> 1, \"äºŒçº§è¯„è®º\" -> 2\n",
    "                if 'comment_level_text' in df.columns:\n",
    "                    df['comment_level'] = df['comment_level_text'].apply(\n",
    "                        lambda x: 1 if x == 'ä¸€çº§è¯„è®º' else (2 if x == 'äºŒçº§è¯„è®º' else 1)\n",
    "                    )\n",
    "                else:\n",
    "                    df['comment_level'] = 1\n",
    "                \n",
    "                # è®¡ç®—äºŒçº§å›å¤æ•°\n",
    "                second_level_counts = df[df['comment_level'] == 2].groupby('replied_user').size()\n",
    "                df['second_level_reply_count'] = df.apply(\n",
    "                    lambda row: second_level_counts.get(row['user_nickname'], 0) \n",
    "                    if row['comment_level'] == 1 else None, \n",
    "                    axis=1\n",
    "                )\n",
    "                \n",
    "                # ç¡®ä¿æ‰€æœ‰å¿…è¦åˆ—å­˜åœ¨\n",
    "                for col in standard_cols:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = None\n",
    "                        \n",
    "                df['ip'] = None\n",
    "                df['post_title'] = post_title\n",
    "                df['source'] = 'Bç«™'\n",
    "                df = df.reindex(columns=standard_cols + ['post_title','source'])\n",
    "                bili_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†Bç«™æ–‡ä»¶ {file} æ—¶å‡ºé”™: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "    bili_all = pd.concat(bili_dfs, ignore_index=True) if bili_dfs else pd.DataFrame(columns=standard_cols + ['post_title','source'])\n",
    "\n",
    "    # å¤„ç†å°çº¢ä¹¦æ•°æ®\n",
    "    xhs_dfs = []\n",
    "    for file in os.listdir(folder_xhs):\n",
    "        if file.endswith('.xlsx'):\n",
    "            try:\n",
    "                print(f\"å¤„ç†å°çº¢ä¹¦æ–‡ä»¶: {file}\")\n",
    "                # å…ˆè¯»å–ç¬¬ä¸€è¡Œæœ€åä¸€åˆ—ä»¥è·å–å¸–å­æ ‡é¢˜\n",
    "                temp = pd.read_excel(os.path.join(folder_xhs, file), header=None)\n",
    "                post_title = str(temp.iloc[0, -1])\n",
    "                # å®é™…æ•°æ®ä»ç¬¬äºŒè¡Œå¼€å§‹ï¼ŒåŒæ ·å¯èƒ½æ²¡æœ‰æ ‡é¢˜è¡Œ\n",
    "                df = pd.read_excel(os.path.join(folder_xhs, file), skiprows=1, header=None)\n",
    "                \n",
    "                # æ‰“å°åˆ—å†…å®¹ä»¥ä¾¿è°ƒè¯•\n",
    "                print(f\"å°çº¢ä¹¦æ–‡ä»¶åˆ—å†…å®¹ç¤ºä¾‹: {df.iloc[0].tolist() if not df.empty else 'ç©ºæ–‡ä»¶'}\")\n",
    "                \n",
    "                # æ ¹æ®ä½ç½®ç›´æ¥æŒ‡å®šåˆ—å - æ ¹æ®å¸¸è§ç»“æ„æ¨æ–­\n",
    "                try:\n",
    "                    column_names = {\n",
    "                        0: 'user_nickname',  # ç¬¬1åˆ—: ç”¨æˆ·æ˜µç§°\n",
    "                        1: 'comment_text',   # ç¬¬2åˆ—: è¯„è®ºå†…å®¹\n",
    "                        2: 'replied_user',   # ç¬¬3åˆ—: è¢«å›å¤ç”¨æˆ·\n",
    "                        3: 'comment_level_text', # ç¬¬4åˆ—: è¯„è®ºå±‚çº§æè¿°\n",
    "                        4: 'ip',             # ç¬¬5åˆ—: IPåœ°å€\n",
    "                        5: 'likes',          # ç¬¬6åˆ—: ç‚¹èµæ•°\n",
    "                        6: 'second_level_reply_count', #ç¬¬7åˆ—ï¼šäºŒçº§å›å¤æ•°\n",
    "                        7: 'reply_time',     # ç¬¬8åˆ—: æ—¶é—´\n",
    "                        \n",
    "                    }\n",
    "                    \n",
    "                    # é‡å‘½ååˆ—\n",
    "                    df = df.rename(columns=column_names)\n",
    "                    \n",
    "                    # é»˜è®¤æ‰€æœ‰å°çº¢ä¹¦è¯„è®ºä¸ºäºŒçº§è¯„è®ºï¼Œé™¤éèƒ½ç¡®å®šå±‚çº§\n",
    "                    df['comment_level'] = 2\n",
    "                    # å¦‚æœ replied_user æœ‰å€¼ï¼Œåˆ™å¯èƒ½æ˜¯ä¸€çº§è¯„è®º\n",
    "                    if 'replied_user' in df.columns:\n",
    "                        df.loc[df['second_level_reply_count'].notna() & (df['second_level_reply_count'] != ''), 'comment_level'] = 1\n",
    "                except Exception as e:\n",
    "                    print(f\"å°çº¢ä¹¦åˆ—åæ˜ å°„é”™è¯¯: {e}\")\n",
    "                    # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨æ›´ä¿å®ˆçš„æ–¹æ³•æ˜ å°„åˆ—\n",
    "                    actual_cols = df.columns.tolist()\n",
    "                    for i, col in enumerate(actual_cols):\n",
    "                        if i < len(['user_nickname', 'comment_text', 'replied_user', 'likes', 'reply_time', 'ip']):\n",
    "                            df = df.rename(columns={col: ['user_nickname', 'comment_text', 'replied_user', 'likes', 'reply_time', 'ip'][i]})\n",
    "                    df['comment_level'] = 1\n",
    "                \n",
    "                # ç¡®ä¿æ‰€æœ‰å¿…è¦åˆ—å­˜åœ¨\n",
    "                for col in standard_cols:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = None\n",
    "                \n",
    "                # å°†å°çº¢ä¹¦æ—¶é—´ä»å„ç§æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼\n",
    "                if 'reply_time' in df.columns and df['reply_time'].notna().any():\n",
    "                    try:\n",
    "                        df['reply_time'] = pd.to_datetime(df['reply_time'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "                    except:\n",
    "                        print(\"è­¦å‘Š: å°çº¢ä¹¦æ—¶é—´æ ¼å¼è½¬æ¢å¤±è´¥\")\n",
    "                \n",
    "                df['gender'] = None \n",
    "                df['user_level'] = None\n",
    "                df['post_title'] = post_title\n",
    "                df['source'] = 'å°çº¢ä¹¦'\n",
    "                df = df.reindex(columns=standard_cols + ['post_title','source'])\n",
    "                xhs_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†å°çº¢ä¹¦æ–‡ä»¶ {file} æ—¶å‡ºé”™: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "    xhs_all = pd.concat(xhs_dfs, ignore_index=True) if xhs_dfs else pd.DataFrame(columns=standard_cols + ['post_title','source'])\n",
    "\n",
    "    # åˆå¹¶æ•°æ®\n",
    "    combined_df = pd.concat([bili_all, xhs_all], ignore_index=True)\n",
    "    print(f\"åˆå¹¶æ•°æ®é›†å¤§å°: {combined_df.shape}\")\n",
    "    return combined_df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    try:\n",
    "        # è¯„è®ºå­—æ•°ç»Ÿè®¡\n",
    "        df['comment_length'] = df['comment_text'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "        \n",
    "        # æ˜¯å¦å¸¦è¡¨æƒ…ï¼ˆåŒ¹é… [xxx]ï¼‰\n",
    "        df['has_emoji'] = df['comment_text'].apply(\n",
    "            lambda x: 'æ˜¯' if pd.notnull(x) and re.search(r'\\[[^]]*\\]', str(x)) else 'å¦'\n",
    "        )\n",
    "        \n",
    "        # Bç«™è¯„è®ºå‘å¸ƒæ—¶æ®µï¼šæ—©/ä¸­/æ™šï¼ˆåªå¯¹ Bç«™æœ‰æ•ˆï¼‰\n",
    "        df['time_slot'] = None\n",
    "        mask_bili = (df['source'] == 'Bç«™') & df['reply_time'].notnull()\n",
    "        \n",
    "        # ç¡®ä¿Bç«™æ—¶é—´æ•°æ®æ˜¯datetimeæ ¼å¼\n",
    "        if mask_bili.any():\n",
    "            try:\n",
    "                # å…ˆç¡®ä¿æ—¶é—´åˆ—æ˜¯å­—ç¬¦ä¸²\n",
    "                df.loc[mask_bili, 'reply_time'] = df.loc[mask_bili, 'reply_time'].astype(str)\n",
    "                # å°è¯•è½¬æ¢ä¸ºdatetime\n",
    "                df.loc[mask_bili, 'reply_time_dt'] = pd.to_datetime(df.loc[mask_bili, 'reply_time'], errors='coerce')\n",
    "                \n",
    "                # åŸºäºè½¬æ¢åçš„datetimeç¡®å®šæ—¶æ®µ\n",
    "                df.loc[mask_bili, 'time_slot'] = df.loc[mask_bili, 'reply_time_dt'].apply(\n",
    "                    lambda t: 'æ—©' if pd.notnull(t) and t.hour < 12 \n",
    "                            else ('ä¸­' if pd.notnull(t) and t.hour < 18 \n",
    "                            else ('æ™š' if pd.notnull(t) else None))\n",
    "                )\n",
    "                # åˆ é™¤ä¸´æ—¶åˆ—\n",
    "                df.drop('reply_time_dt', axis=1, inplace=True, errors='ignore')\n",
    "            except Exception as e:\n",
    "                print(f\"æ—¶é—´æ®µå¤„ç†é”™è¯¯: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # ç”¨æˆ·ç­‰çº§è½¬æ¢ï¼ˆä»… Bç«™ï¼‰\n",
    "        df['user_level_converted'] = None\n",
    "        try:\n",
    "            # ç¡®ä¿ç”¨æˆ·ç­‰çº§æ˜¯æ•°å€¼å‹\n",
    "            mask_bili_level = (df['source'] == 'Bç«™') & df['user_level'].notnull()\n",
    "            if mask_bili_level.any():\n",
    "                df.loc[mask_bili_level, 'user_level'] = pd.to_numeric(df.loc[mask_bili_level, 'user_level'], errors='coerce')\n",
    "                \n",
    "                df['user_level_converted'] = df.apply(\n",
    "                    lambda row: 'èµ„æ·±ç”¨æˆ·' if (row['source'] == 'Bç«™' \n",
    "                                            and pd.notnull(row['user_level']) \n",
    "                                            and pd.to_numeric(row['user_level'], errors='coerce') >= 4)\n",
    "                    else ('æ™®é€šç”¨æˆ·' if (row['source'] == 'Bç«™' and pd.notnull(row['user_level'])) else None),\n",
    "                    axis=1\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"ç”¨æˆ·ç­‰çº§è½¬æ¢é”™è¯¯: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        # äº’åŠ¨å€¼ï¼šå°çº¢ä¹¦äºŒçº§è¯„è®ºæ•°/10ï¼›Bç«™äºŒçº§è¯„è®ºæ•°\n",
    "        df['interaction_score'] = 0  # é»˜è®¤å€¼è®¾ä¸º0\n",
    "        try:\n",
    "            # å®‰å…¨è½¬æ¢second_level_reply_countä¸ºæ•°å€¼\n",
    "            df['second_level_reply_count_num'] = pd.to_numeric(df['second_level_reply_count'], errors='coerce').fillna(0)\n",
    "            \n",
    "            # Bç«™äº’åŠ¨å€¼å°±æ˜¯äºŒçº§è¯„è®ºæ•°\n",
    "            mask_bili = df['source'] == 'Bç«™'\n",
    "            df.loc[mask_bili, 'interaction_score'] = df.loc[mask_bili, 'second_level_reply_count_num']\n",
    "            \n",
    "            # å°çº¢ä¹¦äº’åŠ¨å€¼æ˜¯äºŒçº§è¯„è®ºæ•°/10\n",
    "            mask_xhs = df['source'] == 'å°çº¢ä¹¦'\n",
    "            df.loc[mask_xhs, 'interaction_score'] = df.loc[mask_xhs, 'second_level_reply_count_num'] / 10\n",
    "            \n",
    "            # åˆ é™¤ä¸´æ—¶åˆ—\n",
    "            df.drop('second_level_reply_count_num', axis=1, inplace=True, errors='ignore')\n",
    "        except Exception as e:\n",
    "            print(f\"äº’åŠ¨å€¼è®¡ç®—é”™è¯¯: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return df\n",
    "\n",
    "# è°ƒç”¨ç¤ºä¾‹\n",
    "try:\n",
    "    data_all = unify_data(folder_bili='data/BILI', folder_xhs='data/XHS')\n",
    "    data_all = feature_engineering(data_all)\n",
    "    # é¿å…åŒä¸€æ–‡ä»¶çš„å†™å…¥å†²çª\n",
    "    output_filename = \"final_data_with_features_\" + pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\") + \".xlsx\"\n",
    "    data_all.to_excel(output_filename, index=False)\n",
    "    print(f\"æ•°æ®å·²ä¿å­˜åˆ° {output_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"å¤„ç†å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¤¾äº¤åª’ä½“è¯„è®ºç‚¹èµæ•°é¢„æµ‹ç³»ç»Ÿ - æŠ€æœ¯æ¦‚è¿°\n",
    "\n",
    "## é¡¹ç›®æ¶æ„ä¸åŠŸèƒ½è®¾è®¡\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„è¯„è®ºæ•°æ®åˆ†æç³»ç»Ÿï¼Œä¸“æ³¨äºBç«™å’Œå°çº¢ä¹¦ä¸¤å¤§å¹³å°çš„ç”¨æˆ·è¯„è®ºç‚¹èµè¡Œä¸ºå»ºæ¨¡ã€‚ç³»ç»Ÿé‡‡ç”¨éšæœºæ£®æ—å›å½’ç®—æ³•ï¼Œé€šè¿‡å¤šç»´ç‰¹å¾æå–ä¸åˆ†æï¼Œæ„å»ºç‚¹èµæ•°é‡é¢„æµ‹æ¨¡å‹ï¼Œä¸ºå†…å®¹åˆ›ä½œè€…å’Œç¤¾äº¤åª’ä½“è¿è¥æä¾›æ•°æ®é©±åŠ¨çš„å†³ç­–æ”¯æŒã€‚\n",
    "\n",
    "### æ ¸å¿ƒæŠ€æœ¯æ¡†æ¶\n",
    "\n",
    "- **æ•°æ®å¤„ç†å¼•æ“**ï¼šåŸºäºPandasçš„ETLæµç¨‹ï¼Œå®ç°è·¨å¹³å°æ•°æ®æ•´åˆä¸æ ‡å‡†åŒ–\n",
    "- **ç‰¹å¾å·¥ç¨‹æ¨¡å—**ï¼šè‡ªåŠ¨æå–æ–‡æœ¬ç‰¹å¾ã€æ—¶é—´ç‰¹å¾å’Œç”¨æˆ·ç‰¹å¾ï¼Œæ”¯æŒå¹³å°ç‰¹å®šç‰¹å¾å·®å¼‚åŒ–å¤„ç†\n",
    "- **MLé¢„æµ‹å¼•æ“**ï¼šåŸºäºRandomForestRegressorçš„é›†æˆå­¦ä¹ æ¨¡å‹ï¼Œæ”¯æŒå¢é‡è®­ç»ƒä¸æ¨¡å‹æ›´æ–°\n",
    "- **å¼‚å¸¸å€¼å¤„ç†**ï¼šåŸºäºç™¾åˆ†ä½æ•°çš„è‡ªé€‚åº”è¿‡æ»¤æœºåˆ¶ï¼Œæé«˜æ¨¡å‹ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›\n",
    "- **äº¤äº’å¼ç•Œé¢**ï¼šåŸºäºipywidgetsçš„é€‰é¡¹å¡å¼å“åº”ç•Œé¢ï¼Œæ”¯æŒåŠ¨æ€è¡¨å•è°ƒæ•´å’Œå®æ—¶é¢„æµ‹\n",
    "\n",
    "### æ•°æ®æµä¸å¤„ç†ç®¡é“\n",
    "\n",
    "1. **æ•°æ®è·å–ä¸åˆæ­¥æ¸…æ´—**\n",
    "   - è‡ªåŠ¨è¯†åˆ«Bç«™/å°çº¢ä¹¦æ•°æ®æ ¼å¼å¹¶è¿›è¡Œç»Ÿä¸€æ ‡å‡†åŒ–\n",
    "   - æ™ºèƒ½å¤„ç†ç¼ºå¤±å€¼ã€æ ¼å¼è½¬æ¢å’Œå­—æ®µæ˜ å°„\n",
    "   - ç»Ÿä¸€è¯„è®ºå±‚çº§ä½“ç³»å’Œæ—¶é—´æˆ³æ ¼å¼\n",
    "\n",
    "2. **ç‰¹å¾æŠ½å–ä¸è½¬æ¢**\n",
    "   - å¤šç»´åº¦ç‰¹å¾å·¥ç¨‹ï¼šæ–‡æœ¬é•¿åº¦ã€è¡¨æƒ…ç¬¦å·è¯†åˆ«ã€æ—¶æ®µåˆ†æã€ç”¨æˆ·ç­‰çº§æ˜ å°„\n",
    "   - å¹³å°å·®å¼‚åŒ–ç‰¹å¾ï¼šBç«™(å‘å¸ƒæ—¶æ®µã€ç”¨æˆ·ç­‰çº§)ã€å°çº¢ä¹¦(IPåœ°å€å…³è”)\n",
    "   - äº’åŠ¨ä»·å€¼é‡åŒ–ï¼šåŸºäºäºŒçº§è¯„è®ºæ•°çš„äº’åŠ¨ä»·å€¼è¯„ä¼°æŒ‡æ ‡æ„å»º\n",
    "\n",
    "3. **æ¨¡å‹è®­ç»ƒä¸ä¼˜åŒ–**\n",
    "   - æ”¯æŒæ–°æ¨¡å‹è®­ç»ƒå’Œå·²æœ‰æ¨¡å‹å¢é‡æ›´æ–°\n",
    "   - è‡ªåŠ¨è¿‡æ»¤æç«¯å€¼æé«˜æ¨¡å‹ç¨³å®šæ€§ï¼Œå¯é…ç½®è¿‡æ»¤é˜ˆå€¼\n",
    "   - ç‰¹å¾é‡è¦æ€§è¯„ä¼°ä¸å¯è§†åŒ–ï¼Œæä¾›æ¨¡å‹è§£é‡Šæ€§\n",
    "   - æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ç›‘æ§(MSEã€RÂ²)å’Œç»“æœå¯è§†åŒ–\n",
    "\n",
    "4. **é¢„æµ‹ä¸ç»“æœè¾“å‡º**\n",
    "   - å®æ—¶è¯„è®ºç‚¹èµæ½œåŠ›è¯„ä¼°\n",
    "   - æ ¹æ®ä¸åŒå¹³å°åŠ¨æ€è°ƒæ•´é¢„æµ‹å‚æ•°\n",
    "   - æä¾›é¢„æµ‹ç»“æœè®°å½•ä¸å¯¼å‡º\n",
    "   - æ”¯æŒæ¨¡å‹å¯¹æ¯”å’Œé¢„æµ‹è¿½æº¯\n",
    "\n",
    "## ç³»ç»Ÿäº®ç‚¹ä¸æŠ€æœ¯ä»·å€¼\n",
    "\n",
    "- **æ™ºèƒ½æ•°æ®é€‚é…**ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶é€‚é…ä¸¤å¤§å¹³å°ä¸åŒçš„æ•°æ®æ ¼å¼ä¸ç‰¹å¾ç»“æ„\n",
    "- **å¼‚å¸¸å€¼è‡ªé€‚åº”å¤„ç†**ï¼šé€šè¿‡å¯é…ç½®çš„ç™¾åˆ†ä½é˜ˆå€¼è¿‡æ»¤æç«¯ç‚¹èµæ•°æ®ï¼Œæœ‰æ•ˆæå‡æ¨¡å‹å‡†ç¡®æ€§\n",
    "- **ç‰¹å¾å·®å¼‚åŒ–å¤„ç†**ï¼šé’ˆå¯¹ä¸åŒå¹³å°çš„ç‰¹æ€§è¿›è¡Œä¸ªæ€§åŒ–ç‰¹å¾å·¥ç¨‹å’Œé¢„æµ‹æµç¨‹\n",
    "- **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**ï¼šæ”¯æŒæ—¶é—´æˆ³å‘½åå’Œæ¨¡å‹è¿­ä»£ï¼Œè·Ÿè¸ªæ¨¡å‹æ¼”åŒ–è¿‡ç¨‹\n",
    "- **ç»†ç²’åº¦ç‰¹å¾é‡è¦æ€§åˆ†æ**ï¼šæä¾›è¯¦ç»†çš„ç‰¹å¾å½±å“åŠ›åˆ†æï¼ŒæŒ‡å¯¼å†…å®¹ä¼˜åŒ–ç­–ç•¥\n",
    "\n",
    "é€šè¿‡æ•´åˆæ•°æ®ç§‘å­¦å’Œäººæœºäº¤äº’æŠ€æœ¯ï¼Œè¯¥ç³»ç»Ÿä¸ºç¤¾äº¤åª’ä½“å†…å®¹åˆ›ä½œå’Œè¿è¥æä¾›äº†æ•°æ®é©±åŠ¨çš„åˆ†æå·¥å…·ï¼Œæ”¯æŒä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒå†åˆ°ç‚¹èµé¢„æµ‹çš„å…¨æµç¨‹åº”ç”¨åœºæ™¯ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨å¤æ‚å¤šå˜çš„ç¤¾äº¤åª’ä½“ç¯å¢ƒä¸­åšå‡ºæ›´æ˜æ™ºçš„å†…å®¹å†³ç­–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ef98f62c514f438d6793d89942d196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Text(value='final_data_with_features_20250401_170728.xlsx', description='æ–‡ä»¶è·¯å¾„:', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# ç¡®ä¿modelsæ–‡ä»¶å¤¹å­˜åœ¨\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "    print(\"å·²åˆ›å»ºmodelsæ–‡ä»¶å¤¹\")\n",
    "\n",
    "# 1. å¯¼å…¥æ•°æ®é›†å¹¶è¿›è¡Œé¢„å¤„ç†\n",
    "def load_data(file_path):\n",
    "    \"\"\"åŠ è½½æ•°æ®é›†å¹¶è¿›è¡ŒåŸºæœ¬é¢„å¤„ç†\"\"\"\n",
    "    print(f\"æ­£åœ¨åŠ è½½æ•°æ®: {file_path}\")\n",
    "    \n",
    "    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦ä¸ºç©º\n",
    "    if not file_path or file_path.strip() == '':\n",
    "        print(\"é”™è¯¯: æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º\")\n",
    "        print(\"è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶è·¯å¾„\")\n",
    "        return None\n",
    "    \n",
    "    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æœ‰æ•ˆ\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ '{file_path}'\")\n",
    "        print(\"è¯·ç¡®è®¤æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç¡®ä¿æ–‡ä»¶å·²ä¿å­˜åœ¨æŒ‡å®šä½ç½®ã€‚\")\n",
    "        print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯\n",
    "        print(f\"æ•°æ®é›†å¤§å°: {df.shape}\")\n",
    "        print(\"\\næ•°æ®é›†åˆ—:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"- {col}: {df[col].dtype}\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}\")\n",
    "        print(\"æç¤º: è¯·ç¡®ä¿æ–‡ä»¶æ ¼å¼æ­£ç¡®ä¸”æœªè¢«å…¶ä»–ç¨‹åºå ç”¨ã€‚\")\n",
    "        return None\n",
    "\n",
    "# è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹\n",
    "def get_available_models():\n",
    "    \"\"\"è·å–modelsæ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å¯ç”¨çš„.pklæ¨¡å‹æ–‡ä»¶\"\"\"\n",
    "    model_files = glob.glob('models/*.pkl')\n",
    "    return [os.path.basename(f) for f in model_files]\n",
    "\n",
    "# åŠ è½½ä¿å­˜çš„æ¨¡å‹\n",
    "def load_model(model_name):\n",
    "    \"\"\"ä»modelsæ–‡ä»¶å¤¹åŠ è½½æŒ‡å®šçš„æ¨¡å‹\"\"\"\n",
    "    try:\n",
    "        model_path = os.path.join('models', model_name)\n",
    "        with open(model_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 2. æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹\n",
    "def preprocess_data(df):\n",
    "    \"\"\"å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹\"\"\"\n",
    "    # å¤åˆ¶ä¸€ä»½æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # è½¬æ¢åˆ†ç±»ç‰¹å¾ä¸ºæ•°å€¼å‹\n",
    "    if 'gender' in df_processed.columns:\n",
    "        gender_map = {'ç”·': 1, 'å¥³': 2, 'ä¿å¯†': 0}\n",
    "        df_processed['gender_num'] = df_processed['gender'].map(gender_map).fillna(0)\n",
    "    \n",
    "    # è½¬æ¢æ—¶é—´ä¸ºæ•°å€¼ç‰¹å¾\n",
    "    if 'reply_time' in df_processed.columns:\n",
    "        df_processed['reply_time'] = pd.to_datetime(df_processed['reply_time'], errors='coerce')\n",
    "        df_processed['reply_hour'] = df_processed['reply_time'].dt.hour.fillna(-1)\n",
    "        df_processed['reply_dayofweek'] = df_processed['reply_time'].dt.dayofweek.fillna(-1)\n",
    "    \n",
    "    # è½¬æ¢æ—¶é—´æ®µä¸ºæ•°å€¼\n",
    "    if 'time_slot' in df_processed.columns:\n",
    "        time_slot_map = {'æ—©': 0, 'ä¸­': 1, 'æ™š': 2}\n",
    "        df_processed['time_slot_num'] = df_processed['time_slot'].map(time_slot_map).fillna(-1)\n",
    "    \n",
    "    # è½¬æ¢æ¥æºä¸ºæ•°å€¼\n",
    "    if 'source' in df_processed.columns:\n",
    "        source_map = {'Bç«™': 0, 'å°çº¢ä¹¦': 1}\n",
    "        df_processed['source_num'] = df_processed['source'].map(source_map).fillna(-1)\n",
    "    \n",
    "    # è½¬æ¢è¡¨æƒ…ç‰¹å¾\n",
    "    if 'has_emoji' in df_processed.columns:\n",
    "        df_processed['has_emoji_num'] = df_processed['has_emoji'].map({'æ˜¯': 1, 'å¦': 0}).fillna(0)\n",
    "    \n",
    "    # ç¡®ä¿ç‚¹èµæ•°æ˜¯æ•°å€¼å‹\n",
    "    if 'likes' in df_processed.columns:\n",
    "        df_processed['likes'] = pd.to_numeric(df_processed['likes'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # ç”¨æˆ·ç­‰çº§è½¬æ¢ä¸ºæ•°å€¼\n",
    "    if 'user_level_converted' in df_processed.columns:\n",
    "        level_map = {'èµ„æ·±ç”¨æˆ·': 1, 'æ™®é€šç”¨æˆ·': 0}\n",
    "        df_processed['user_level_converted_num'] = df_processed['user_level_converted'].map(level_map).fillna(-1)\n",
    "    \n",
    "    # å¤„ç†ç¼ºå¤±å€¼\n",
    "    numeric_features = ['comment_length', 'likes', 'interaction_score']\n",
    "    for feature in numeric_features:\n",
    "        if feature in df_processed.columns:\n",
    "            df_processed[feature] = pd.to_numeric(df_processed[feature], errors='coerce').fillna(0)\n",
    "    \n",
    "    print(\"é¢„å¤„ç†å®Œæˆ!\")\n",
    "    return df_processed\n",
    "\n",
    "# 3. æ¨¡å‹è®­ç»ƒ\n",
    "def train_model(df, test_size=0.2, random_state=42, existing_model=None, filter_outliers=True, percentile_threshold=99):\n",
    "    \"\"\"è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹å¹¶è¿”å›æ¨¡å‹å’Œè¯„ä¼°æŒ‡æ ‡\"\"\"\n",
    "    plt.rc(\"font\", family='MicroSoft YaHei', weight=\"bold\")\n",
    "    \n",
    "    # é€‰æ‹©ç‰¹å¾åˆ—ï¼Œå»é™¤ä¸é€‚åˆä½œä¸ºç‰¹å¾çš„åˆ—\n",
    "    features = [col for col in df.columns if col.endswith('_num') or \n",
    "                col in ['comment_length', 'interaction_score', 'reply_hour', 'reply_dayofweek']]\n",
    "    \n",
    "    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½å­˜åœ¨\n",
    "    features = [f for f in features if f in df.columns]\n",
    "    \n",
    "    print(f\"ä½¿ç”¨ä»¥ä¸‹ç‰¹å¾è¿›è¡Œè®­ç»ƒ: {features}\")\n",
    "    \n",
    "    # è¿‡æ»¤å¼‚å¸¸å€¼\n",
    "    original_size = len(df)\n",
    "    if filter_outliers and 'likes' in df.columns:\n",
    "        # æ˜¾ç¤ºç‚¹èµæ•°åˆ†å¸ƒæƒ…å†µ\n",
    "        print(\"\\nç‚¹èµæ•°ç»Ÿè®¡:\")\n",
    "        print(f\"- æœ€å°å€¼: {df['likes'].min()}\")\n",
    "        print(f\"- æœ€å¤§å€¼: {df['likes'].max()}\")\n",
    "        print(f\"- å¹³å‡å€¼: {df['likes'].mean():.2f}\")\n",
    "        print(f\"- ä¸­ä½æ•°: {df['likes'].median()}\")\n",
    "        \n",
    "        # è®¡ç®—ç™¾åˆ†ä½æ•°é˜ˆå€¼\n",
    "        likes_threshold = df['likes'].quantile(percentile_threshold/100)\n",
    "        print(f\"- {percentile_threshold}ç™¾åˆ†ä½æ•°: {likes_threshold}\")\n",
    "        \n",
    "        # è¿‡æ»¤æç«¯ç‚¹èµæ•°\n",
    "        filtered_df = df[df['likes'] <= likes_threshold].copy()\n",
    "        \n",
    "        # æŠ¥å‘Šè¿‡æ»¤æƒ…å†µ\n",
    "        filtered_size = len(filtered_df)\n",
    "        filtered_count = original_size - filtered_size\n",
    "        \n",
    "        print(f\"\\nå·²è¿‡æ»¤ {filtered_count} æ¡å¼‚å¸¸ç‚¹èµæ•°æ® ({filtered_count/original_size*100:.2f}%)\")\n",
    "        print(f\"è¿‡æ»¤åæ•°æ®é›†å¤§å°: {filtered_size}\")\n",
    "        \n",
    "        # ä½¿ç”¨è¿‡æ»¤åçš„æ•°æ®é›†\n",
    "        df = filtered_df\n",
    "        \n",
    "        # ç»˜åˆ¶è¿‡æ»¤å‰åçš„ç‚¹èµæ•°åˆ†å¸ƒ\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df['likes'], kde=True)\n",
    "        plt.title('è¿‡æ»¤åç‚¹èµæ•°åˆ†å¸ƒ')\n",
    "        plt.xlabel('ç‚¹èµæ•°')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(x=df['likes'])\n",
    "        plt.title('è¿‡æ»¤åç‚¹èµæ•°ç®±çº¿å›¾')\n",
    "        plt.xlabel('ç‚¹èµæ•°')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['likes']\n",
    "    \n",
    "    # æ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "    if existing_model is not None:\n",
    "        print(f\"ä½¿ç”¨å·²æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒ\")\n",
    "        model = existing_model\n",
    "        # ç»§ç»­è®­ç»ƒç°æœ‰æ¨¡å‹\n",
    "        model.n_estimators += 50  # å¢åŠ æ›´å¤šæ ‘\n",
    "        model.fit(X_train, y_train)\n",
    "    else:\n",
    "        print(f\"è®­ç»ƒæ–°æ¨¡å‹\")\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # é¢„æµ‹å’Œè¯„ä¼°\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"æ¨¡å‹è®­ç»ƒå®Œæˆ:\")\n",
    "    print(f\"- å‡æ–¹è¯¯å·® (MSE): {mse:.2f}\")\n",
    "    print(f\"- RÂ² è¯„åˆ†: {r2:.2f}\")\n",
    "    \n",
    "    # ç‰¹å¾é‡è¦æ€§\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nç‰¹å¾é‡è¦æ€§:\")\n",
    "    display(feature_importance)\n",
    "    \n",
    "    # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "    plt.title('ç‰¹å¾é‡è¦æ€§')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ç»˜åˆ¶é¢„æµ‹å€¼ä¸å®é™…å€¼å¯¹æ¯”æ•£ç‚¹å›¾\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "    plt.xlabel('å®é™…ç‚¹èµæ•°')\n",
    "    plt.ylabel('é¢„æµ‹ç‚¹èµæ•°')\n",
    "    plt.title('å®é™…ç‚¹èµæ•° vs é¢„æµ‹ç‚¹èµæ•°')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, feature_importance\n",
    "# 4. åˆ›å»ºç”¨äºé¢„æµ‹çš„å‡½æ•°\n",
    "def prepare_input_for_prediction(input_data, feature_names):\n",
    "    \"\"\"å‡†å¤‡è¾“å…¥æ•°æ®ç”¨äºé¢„æµ‹\"\"\"\n",
    "    # åˆ›å»ºåŒ…å«æ‰€æœ‰ç‰¹å¾çš„DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½å­˜åœ¨äºè¾“å…¥æ•°æ®ä¸­\n",
    "    for feature in feature_names:\n",
    "        if feature not in input_df.columns:\n",
    "            input_df[feature] = 0\n",
    "    \n",
    "    # åªé€‰æ‹©æ¨¡å‹ä½¿ç”¨çš„ç‰¹å¾\n",
    "    return input_df[feature_names]\n",
    "\n",
    "def predict_likes(model, input_data, feature_names):\n",
    "    \"\"\"ä½¿ç”¨æ¨¡å‹é¢„æµ‹ç‚¹èµæ•°\"\"\"\n",
    "    # å‡†å¤‡è¾“å…¥æ•°æ®\n",
    "    X = prepare_input_for_prediction(input_data, feature_names)\n",
    "    \n",
    "    # è¿›è¡Œé¢„æµ‹\n",
    "    prediction = model.predict(X)[0]\n",
    "    \n",
    "    return max(0, round(prediction))  # ç¡®ä¿ç‚¹èµæ•°ä¸ºéè´Ÿæ•´æ•°\n",
    "\n",
    "# 5. åˆ›å»ºUIç•Œé¢\n",
    "def create_ui():\n",
    "    \"\"\"åˆ›å»ºç”¨æˆ·ç•Œé¢\"\"\"\n",
    "    # åˆ›å»ºé€‰é¡¹å¡\n",
    "    tab = widgets.Tab()\n",
    "    tab_load = widgets.VBox()\n",
    "    tab_predict = widgets.VBox()\n",
    "    \n",
    "    # ===== é€‰é¡¹å¡1: åŠ è½½æ•°æ®é›†å’Œè®­ç»ƒæ¨¡å‹ =====\n",
    "    xlsx_files = glob.glob(\"*.xlsx\")\n",
    "    latest_file = max(xlsx_files, key=os.path.getmtime) if xlsx_files else \"\"\n",
    "    file_path_input = widgets.Text(\n",
    "        value=latest_file,\n",
    "        description='æ–‡ä»¶è·¯å¾„:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†\n",
    "    model_options = ['è®­ç»ƒæ–°æ¨¡å‹'] + get_available_models()\n",
    "    model_dropdown = widgets.Dropdown(\n",
    "        options=model_options,\n",
    "        value='è®­ç»ƒæ–°æ¨¡å‹',\n",
    "        description='é€‰æ‹©æ¨¡å‹:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    \n",
    "    load_button = widgets.Button(\n",
    "        description='åŠ è½½å¹¶è®­ç»ƒæ¨¡å‹',\n",
    "        button_style='primary',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    filter_outliers = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='è¿‡æ»¤å¼‚å¸¸ç‚¹èµå€¼',\n",
    "    disabled=False\n",
    "    )\n",
    "\n",
    "    percentile_slider = widgets.IntSlider(\n",
    "        value=99,\n",
    "        min=90,\n",
    "        max=99,\n",
    "        step=1,\n",
    "        description='è¿‡æ»¤ç™¾åˆ†ä½:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    model_output = widgets.Output()\n",
    "    \n",
    "    tab_load.children = [file_path_input, model_dropdown, \n",
    "                     widgets.HBox([filter_outliers, percentile_slider]),\n",
    "                     load_button, model_output]\n",
    "    \n",
    "    # ===== é€‰é¡¹å¡2: æ‰‹åŠ¨è¾“å…¥æ•°æ®è¿›è¡Œé¢„æµ‹ =====\n",
    "    # åˆ›å»ºé¢„æµ‹æ—¶çš„æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†\n",
    "    predict_model_dropdown = widgets.Dropdown(\n",
    "        options=get_available_models() if get_available_models() else ['è¯·å…ˆè®­ç»ƒæ¨¡å‹'],\n",
    "        value=get_available_models()[0] if get_available_models() else 'è¯·å…ˆè®­ç»ƒæ¨¡å‹',\n",
    "        description='é€‰æ‹©æ¨¡å‹:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºè¾“å…¥å­—æ®µ\n",
    "    comment_text = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='è¯·è¾“å…¥è¯„è®ºå†…å®¹',\n",
    "        description='è¯„è®ºå†…å®¹:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='500px', height='100px')\n",
    "    )\n",
    "    \n",
    "    comment_length = widgets.IntText(\n",
    "        value=0,\n",
    "        description='è¯„è®ºå­—æ•°:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    has_emoji = widgets.Dropdown(\n",
    "        options=[('å¦', 0), ('æ˜¯', 1)],\n",
    "        value=0,\n",
    "        description='å¸¦è¡¨æƒ…:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    source = widgets.Dropdown(\n",
    "        options=[('Bç«™', 0), ('å°çº¢ä¹¦', 1)],\n",
    "        value=0,\n",
    "        description='æ¥æº:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    # Bç«™ç‰¹æœ‰å­—æ®µ\n",
    "    time_slot = widgets.Dropdown(\n",
    "        options=[('æ—©', 0), ('ä¸­', 1), ('æ™š', 2)],\n",
    "        value=2,\n",
    "        description='å‘å¸ƒæ—¶æ®µ:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    user_level = widgets.Dropdown(\n",
    "        options=[('æ™®é€šç”¨æˆ·', 0), ('èµ„æ·±ç”¨æˆ·', 1)],\n",
    "        value=0,\n",
    "        description='ç”¨æˆ·ç­‰çº§:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    # å°çº¢ä¹¦ç‰¹æœ‰å­—æ®µ\n",
    "    ip_address = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='å¦‚: å¹¿ä¸œ',\n",
    "        description='IPåœ°å€:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    likes = widgets.IntText(\n",
    "        value=0,\n",
    "        description='å®é™…ç‚¹èµæ•°(å¯é€‰):',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    predict_button = widgets.Button(\n",
    "        description='é¢„æµ‹ç‚¹èµæ•°',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    record_button = widgets.Button(\n",
    "        description='è®°å½•æœ¬æ¬¡é¢„æµ‹',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    prediction_output = widgets.Output()\n",
    "    \n",
    "    # åˆ›å»ºæ¥æºç‰¹å®šå­—æ®µçš„å®¹å™¨\n",
    "    source_specific_container = widgets.HBox([time_slot, user_level])\n",
    "    \n",
    "    tab_predict.children = [\n",
    "        predict_model_dropdown,\n",
    "        widgets.HBox([comment_text]),\n",
    "        widgets.HBox([comment_length, has_emoji]),\n",
    "        widgets.HBox([source]),\n",
    "        source_specific_container,\n",
    "        widgets.HBox([likes]),\n",
    "        widgets.HBox([predict_button, record_button]),\n",
    "        prediction_output\n",
    "    ]\n",
    "    \n",
    "    # è®¾ç½®é€‰é¡¹å¡\n",
    "    tab.children = [tab_load, tab_predict]\n",
    "    tab.set_title(0, 'è®­ç»ƒæ¨¡å‹')\n",
    "    tab.set_title(1, 'ç‚¹èµé¢„æµ‹')\n",
    "    \n",
    "    # å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹å’Œç‰¹å¾åç§°\n",
    "    global_vars = {\n",
    "        'model': None,\n",
    "        'feature_names': None,\n",
    "        'predictions': []  # å­˜å‚¨å†å²é¢„æµ‹\n",
    "    }\n",
    "\n",
    "    # å¤„ç†æ¥æºå˜æ›´çš„å‡½æ•°\n",
    "    def on_source_change(change):\n",
    "        if change['name'] == 'value':\n",
    "            # å…ˆæ¸…ç©ºå®¹å™¨\n",
    "            source_specific_container.children = []\n",
    "            \n",
    "            # æ ¹æ®é€‰æ‹©çš„æ¥æºå¡«å……å®¹å™¨\n",
    "            if change['new'] == 0:  # Bç«™\n",
    "                source_specific_container.children = [time_slot, user_level]\n",
    "            else:  # å°çº¢ä¹¦\n",
    "                source_specific_container.children = [ip_address]\n",
    "\n",
    "    # æ›´æ–°é¢„æµ‹æ¨¡å‹ä¸‹æ‹‰èœå•\n",
    "    def update_predict_model_dropdown():\n",
    "        models = get_available_models()\n",
    "        if models:\n",
    "            predict_model_dropdown.options = models\n",
    "            predict_model_dropdown.value = models[0]\n",
    "        else:\n",
    "            predict_model_dropdown.options = ['è¯·å…ˆè®­ç»ƒæ¨¡å‹']\n",
    "            predict_model_dropdown.value = 'è¯·å…ˆè®­ç»ƒæ¨¡å‹'\n",
    "\n",
    "    # æŒ‰é’®äº‹ä»¶å¤„ç†\n",
    "    def on_load_button_clicked(b):\n",
    "        with model_output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                # åŠ è½½æ•°æ®\n",
    "                file_path = file_path_input.value.strip()\n",
    "                \n",
    "                # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦ä¸ºç©º\n",
    "                if not file_path:\n",
    "                    print(\"é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶è·¯å¾„\")\n",
    "                    print(\"æç¤º: è¯·åœ¨\\\"æ–‡ä»¶è·¯å¾„\\\"è¾“å…¥æ¡†ä¸­è¾“å…¥Excelæ–‡ä»¶çš„ä½ç½®\")\n",
    "                    return\n",
    "                \n",
    "                df = load_data(file_path)\n",
    "                \n",
    "                # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½æ•°æ®\n",
    "                if df is None:\n",
    "                    return  # load_dataå‡½æ•°å·²ç»æ˜¾ç¤ºäº†é”™è¯¯ä¿¡æ¯\n",
    "                \n",
    "                # æ•°æ®é¢„å¤„ç†\n",
    "                df_processed = preprocess_data(df)\n",
    "                \n",
    "                # ç¡®å®šæ˜¯è®­ç»ƒæ–°æ¨¡å‹è¿˜æ˜¯ç»§ç»­è®­ç»ƒå·²æœ‰æ¨¡å‹\n",
    "                existing_model = None\n",
    "                if model_dropdown.value != 'è®­ç»ƒæ–°æ¨¡å‹':\n",
    "                    print(f\"åŠ è½½å·²æœ‰æ¨¡å‹: {model_dropdown.value}\")\n",
    "                    existing_model = load_model(model_dropdown.value)\n",
    "                    if existing_model is None:\n",
    "                        print(\"åŠ è½½æ¨¡å‹å¤±è´¥ï¼Œå°†è®­ç»ƒæ–°æ¨¡å‹\")\n",
    "                \n",
    "                # è®­ç»ƒæ¨¡å‹\n",
    "                # ä¿®æ”¹è®­ç»ƒæ¨¡å‹è°ƒç”¨éƒ¨åˆ†\n",
    "                model, feature_importance = train_model(\n",
    "                    df_processed, \n",
    "                    existing_model=existing_model,\n",
    "                    filter_outliers=filter_outliers.value,\n",
    "                    percentile_threshold=percentile_slider.value\n",
    "                )\n",
    "                \n",
    "                # ä¿å­˜æ¨¡å‹å’Œç‰¹å¾åç§°\n",
    "                global_vars['model'] = model\n",
    "                global_vars['feature_names'] = feature_importance['Feature'].tolist()\n",
    "                \n",
    "                # ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                \n",
    "                if model_dropdown.value == 'è®­ç»ƒæ–°æ¨¡å‹':\n",
    "                    model_filename = f\"rf_model_{timestamp}.pkl\"\n",
    "                else:\n",
    "                    # å¦‚æœç»§ç»­è®­ç»ƒå·²æœ‰æ¨¡å‹ï¼Œä¸ºæ–‡ä»¶åæ·»åŠ \"_updated\"åç¼€\n",
    "                    base_name = os.path.splitext(model_dropdown.value)[0]\n",
    "                    model_filename = f\"{base_name}_updated_{timestamp}.pkl\"\n",
    "                \n",
    "                model_path = os.path.join('models', model_filename)\n",
    "                with open(model_path, 'wb') as f:\n",
    "                    pickle.dump(model, f)\n",
    "                print(f\"\\næ¨¡å‹å·²ä¿å­˜åˆ° '{model_path}'\")\n",
    "                \n",
    "                # æ›´æ–°æ¨¡å‹ä¸‹æ‹‰èœå•\n",
    "                model_dropdown.options = ['è®­ç»ƒæ–°æ¨¡å‹'] + get_available_models()\n",
    "                update_predict_model_dropdown()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:\")\n",
    "                print(f\"- {str(e)}\")\n",
    "                print(\"\\nè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…è¦çš„ç‰¹å¾åˆ—ã€‚\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    def on_predict_button_clicked(b):\n",
    "        with prediction_output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ¨¡å‹\n",
    "                if predict_model_dropdown.value == 'è¯·å…ˆè®­ç»ƒæ¨¡å‹':\n",
    "                    print(\"è¯·å…ˆåœ¨'è®­ç»ƒæ¨¡å‹'æ ‡ç­¾é¡µè®­ç»ƒæ¨¡å‹ï¼\")\n",
    "                    return\n",
    "                \n",
    "                # å¦‚æœå…¨å±€å˜é‡ä¸­æ²¡æœ‰æ¨¡å‹ï¼Œæˆ–é€‰æ‹©äº†ä¸åŒçš„æ¨¡å‹ï¼Œåˆ™åŠ è½½é€‰å®šçš„æ¨¡å‹\n",
    "                selected_model = predict_model_dropdown.value\n",
    "                if global_vars['model'] is None or selected_model != getattr(global_vars.get('current_model_name', None), 'value', None):\n",
    "                    print(f\"åŠ è½½æ¨¡å‹: {selected_model}\")\n",
    "                    model = load_model(selected_model)\n",
    "                    if model is None:\n",
    "                        print(\"æ¨¡å‹åŠ è½½å¤±è´¥ï¼\")\n",
    "                        return\n",
    "                    \n",
    "                    # ä»æ¨¡å‹ä¸­è·å–ç‰¹å¾åç§°\n",
    "                    feature_names = [f for f in model.feature_names_in_]\n",
    "                    \n",
    "                    # æ›´æ–°å…¨å±€å˜é‡\n",
    "                    global_vars['model'] = model\n",
    "                    global_vars['feature_names'] = feature_names\n",
    "                    global_vars['current_model_name'] = selected_model\n",
    "                \n",
    "                # æ”¶é›†è¾“å…¥æ•°æ®\n",
    "                input_data = {\n",
    "                    'comment_length': comment_length.value,\n",
    "                    'has_emoji_num': has_emoji.value,\n",
    "                    'source_num': source.value,\n",
    "                    'interaction_score': 0,  # é»˜è®¤å€¼\n",
    "                    'reply_hour': datetime.now().hour,  # å½“å‰å°æ—¶\n",
    "                    'reply_dayofweek': datetime.now().weekday()  # å½“å‰æ˜ŸæœŸå‡ \n",
    "                }\n",
    "                \n",
    "                # æ ¹æ®æ¥æºæ·»åŠ ç‰¹å®šå­—æ®µ\n",
    "                if source.value == 0:  # Bç«™\n",
    "                    input_data['time_slot_num'] = time_slot.value\n",
    "                    input_data['user_level_converted_num'] = user_level.value\n",
    "                else:  # å°çº¢ä¹¦\n",
    "                    # å°çº¢ä¹¦ä¸éœ€è¦æ—¶é—´æ®µå’Œç”¨æˆ·ç­‰çº§ï¼Œä½†å¯èƒ½éœ€è¦IP\n",
    "                    input_data['time_slot_num'] = -1  # é»˜è®¤å€¼\n",
    "                    input_data['user_level_converted_num'] = -1  # é»˜è®¤å€¼\n",
    "                \n",
    "                # é¢„æµ‹ç‚¹èµæ•°\n",
    "                prediction = predict_likes(global_vars['model'], input_data, global_vars['feature_names'])\n",
    "                \n",
    "                print(f\"é¢„æµ‹ç‚¹èµæ•°: {prediction}\")\n",
    "                \n",
    "                # å­˜å‚¨é¢„æµ‹ç»“æœ\n",
    "                prediction_result = {\n",
    "                    'comment_text': comment_text.value,\n",
    "                    'comment_length': comment_length.value,\n",
    "                    'has_emoji': 'æ˜¯' if has_emoji.value == 1 else 'å¦',\n",
    "                    'source': 'Bç«™' if source.value == 0 else 'å°çº¢ä¹¦',\n",
    "                    'predicted_likes': prediction,\n",
    "                    'actual_likes': likes.value if likes.value > 0 else None,\n",
    "                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'model_used': predict_model_dropdown.value\n",
    "                }\n",
    "                \n",
    "                # æ·»åŠ æ¥æºç‰¹å®šä¿¡æ¯\n",
    "                if source.value == 0:  # Bç«™\n",
    "                    prediction_result['time_slot'] = ['æ—©', 'ä¸­', 'æ™š'][time_slot.value]\n",
    "                    prediction_result['user_level'] = 'èµ„æ·±ç”¨æˆ·' if user_level.value == 1 else 'æ™®é€šç”¨æˆ·'\n",
    "                else:  # å°çº¢ä¹¦\n",
    "                    prediction_result['ip_address'] = ip_address.value\n",
    "                \n",
    "                global_vars['predictions'].append(prediction_result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"é¢„æµ‹é”™è¯¯: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    def on_record_button_clicked(b):\n",
    "        with prediction_output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                if not global_vars['predictions']:\n",
    "                    print(\"æ²¡æœ‰å¯è®°å½•çš„é¢„æµ‹ç»“æœï¼\")\n",
    "                    return\n",
    "                \n",
    "                # è·å–æœ€æ–°ä¸€æ¬¡é¢„æµ‹\n",
    "                latest_prediction = global_vars['predictions'][-1]\n",
    "                \n",
    "                # å¦‚æœæä¾›äº†å®é™…ç‚¹èµæ•°ï¼Œæ›´æ–°è®°å½•\n",
    "                if likes.value > 0:\n",
    "                    latest_prediction['actual_likes'] = likes.value\n",
    "                \n",
    "                # è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜\n",
    "                predictions_df = pd.DataFrame(global_vars['predictions'])\n",
    "                output_file = f\"likes_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "                predictions_df.to_excel(output_file, index=False)\n",
    "                \n",
    "                print(f\"é¢„æµ‹è®°å½•å·²ä¿å­˜åˆ°: {output_file}\")\n",
    "                display(predictions_df.tail(5))  # æ˜¾ç¤ºæœ€è¿‘5æ¬¡é¢„æµ‹\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"è®°å½•é”™è¯¯: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    # æ›´æ–°è¯„è®ºå­—æ•°\n",
    "    def update_comment_length(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            comment_length.value = len(change['new'])\n",
    "    \n",
    "    # è¿æ¥äº‹ä»¶å¤„ç†å‡½æ•°\n",
    "    load_button.on_click(on_load_button_clicked)\n",
    "    predict_button.on_click(on_predict_button_clicked)\n",
    "    record_button.on_click(on_record_button_clicked)\n",
    "    comment_text.observe(update_comment_length)\n",
    "    source.observe(on_source_change)\n",
    "    \n",
    "    # åˆå§‹åŒ–ç•Œé¢\n",
    "    on_source_change({'name': 'value', 'new': source.value})\n",
    "    \n",
    "    return tab\n",
    "\n",
    "# 6. ä¸»ç¨‹åº\n",
    "def main():\n",
    "    # åˆ›å»ºå¹¶æ˜¾ç¤ºUI\n",
    "    ui = create_ui()\n",
    "    display(ui)\n",
    "\n",
    "# è¿è¡Œä¸»ç¨‹åº\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
